{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from simulator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_size = 30\n",
    "catalog_size = 100\n",
    "sample_size_day = 4000\n",
    "\n",
    "trace_day1 = gen_irm_trace(sample_size=sample_size_day, catalog_size=catalog_size, power_law_exp=0.8, shuffled=True)\n",
    "trace_day2 = gen_irm_trace(sample_size=sample_size_day, catalog_size=catalog_size, power_law_exp=0.4, shuffled=True)\n",
    "trace_day3 = np.random.randint(low=0, high=catalog_size-1, size=sample_size_day).tolist()\n",
    "# trace_day3 = gen_irm_trace(sample_size=sample_size_day, catalog_size=catalog_size, power_law_exp=0.4, shuffled=True)\n",
    "trace_day4 = gen_irm_trace(sample_size=sample_size_day, catalog_size=catalog_size, power_law_exp=0.7, shuffled=True)\n",
    "trace_day5 = gen_irm_trace(sample_size=sample_size_day, catalog_size=catalog_size, power_law_exp=0.5, shuffled=True)\n",
    "trace_day6 = gen_irm_trace(sample_size=sample_size_day, catalog_size=catalog_size, power_law_exp=0.9, shuffled=True)\n",
    "\n",
    "\n",
    "traces = [trace_day1, trace_day2, trace_day3, trace_day4, trace_day5]\n",
    "\n",
    "switching_points = np.cumsum([len(t) for t in traces])-1 # -1 to compensate for the index starting at 0\n",
    "\n",
    "# Able to switch twice a day\n",
    "# switching_points = np.cumsum([sample_size_day // 2 for _ in range(len(traces)*2)])-1\n",
    "\n",
    "trace = [r for t in traces for r in t]\n",
    "sample_size = len(trace)\n",
    "# switching_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a099ac5cf8dc44b6963cc124ab802082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache_init = init_cache(cache_size, catalog_size)\n",
    "\n",
    "cache_LRU = LRU(cache_size, catalog_size, cache_init)\n",
    "cache_LFU = LFU(cache_size, catalog_size, cache_init)\n",
    "cache_BH = CacheStatic(cache_size, catalog_size, gen_best_static(trace, cache_size))\n",
    "cache_OGD = OGD(cache_size, catalog_size, sample_size)\n",
    "cache_FTPL = FTPL(cache_size, catalog_size, cache_init)\n",
    "\n",
    "OGD_init = lambda cache_size, catalog_size, cache_init: OGD(cache_size, catalog_size, sample_size)\n",
    "experts = (LRU, LFU, OGD_init, FTPL)\n",
    "\n",
    "\n",
    "cache_EP = ExpertsCacheNeq(cache_size, catalog_size, cache_init, experts, init_rnd_expert=False)\n",
    "cache_EP.name = \"Cache EP\"\n",
    "cache_EP_island = ExpertsCacheNeq(cache_size, catalog_size, cache_init, experts, init_rnd_expert=False)\n",
    "cache_EP_island.name = \"EP Island\"\n",
    "cache_EP_island_wr = ExpertsCacheNeq(cache_size, catalog_size, cache_init, experts, init_rnd_expert=False)\n",
    "cache_EP_island_wr.name = \"EP Island + WR\"\n",
    "\n",
    "cache_EP_evict_HS = ExpertsCacheEvict(cache_size, catalog_size, cache_init, alg=\"WM-HS\")\n",
    "cache_EP_evict_HS.name = \"EP evict\"\n",
    "\n",
    "for i, request in tqdm(enumerate(trace), total=len(trace)):\n",
    "    cache_LRU.request(request)\n",
    "    cache_LFU.request(request)\n",
    "    cache_BH.request(request)\n",
    "    cache_OGD.request(request)\n",
    "    cache_FTPL.request(request)\n",
    "    cache_EP.request(request)\n",
    "    cache_EP_island.request(request, switch=i in switching_points, weight_reset=False)\n",
    "    cache_EP_island_wr.request(request, switch=i in switching_points, weight_reset=True)\n",
    "    cache_EP_evict_HS.request(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b19656f69e48ab8db9471a4a7a0881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "plot_comp(\\\n",
    "          cache_LRU,\\\n",
    "          cache_LFU,\\\n",
    "          cache_BH,\\\n",
    "          cache_OGD,\\\n",
    "          cache_FTPL,\\\n",
    "#           cache_EP,\\\n",
    "          cache_EP_island,\\\n",
    "          cache_EP_island_wr,\\\n",
    "          cache_EP_evict_HS,\\\n",
    "         )\n",
    "plt.vlines(switching_points, ymin=0, ymax=1.0, linestyles=\"dashed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_caches(caches, points):\n",
    "    best_caches = []\n",
    "    for p in points:\n",
    "        hits = [cache.get_hitrate()[p] for  cache in caches]\n",
    "        best_cache = caches[hits.index(max(hits))]\n",
    "        best_caches.append(best_cache.get_name())\n",
    "    return best_caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_caches = get_best_caches([cache_LRU, cache_LFU, cache_OGD, cache_FTPL], switching_points)\n",
    "\n",
    "EP_choices = [cache_EP.expert_choices[sp-1] for sp in switching_points]\n",
    "EP_evict_choices = [cache_EP_evict_HS.experts[cache_EP_evict_HS.expert_choices[sp-1]].name for sp in switching_points]\n",
    "EP_island_choices = [cache_EP_island.expert_choices[sp-1] for sp in switching_points]\n",
    "EP_island_choices_wr = [cache_EP_island_wr.expert_choices[sp-1] for sp in switching_points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:\t\t ['OGD', 'LFU', 'FTPL', 'OGD', 'OGD']\n",
      "EP_evict:\t ['FTPL', 'LFU', 'LFU', 'LRU', 'LFU']\n",
      "EP_island:\t ['LRU', 'FTPL', 'OGD', 'OGD', 'OGD']\n",
      "EP_island_wr:\t ['LRU', 'LRU', 'FTPL', 'OGD', 'OGD']\n",
      "Best caches:\t ['LFU', 'LFU', 'LFU', 'OGD', 'OGD']\n"
     ]
    }
   ],
   "source": [
    "print(\"EP:\\t\\t\", EP_choices)\n",
    "print(\"EP_evict:\\t\", EP_evict_choices)\n",
    "print(\"EP_island:\\t\", EP_island_choices)\n",
    "print(\"EP_island_wr:\\t\", EP_island_choices_wr)\n",
    "print(\"Best caches:\\t\", best_caches)\n",
    "# Note: FTPL and LFU have very close performance and depending on the randomness one or the other is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
